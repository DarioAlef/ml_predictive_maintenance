{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7c38b869",
      "metadata": {
        "id": "7c38b869"
      },
      "source": [
        "# Projeto: Seleção e Otimização de Modelos para Manutenção Preditiva de Máquinas\n",
        "\n",
        "### Equipe:\n",
        "- Bruno Da Costa Prianti\n",
        "- Daniel Modesto De Souza\n",
        "- Dário Alef Barros Lima\n",
        "- Karen Letícia Santana Da Silva\n",
        "- Willian Do Nascimento Severiano\n",
        "\n",
        "### Contexto do Projeto\n",
        "\n",
        "A **manutenção preditiva** é um pilar da Indústria 4.0, permitindo a antecipação de falhas em equipamentos para reduzir custos e aumentar a eficiência. A aplicação de **Machine Learning (ML)** neste cenário possibilita a criação de modelos capazes de prever falhas com base em dados de telemetria, transformando a manutenção reativa em uma estratégia proativa.\n",
        "\n",
        "Este projeto documenta o processo sistemático de desenvolvimento de uma solução para prever falhas em máquinas, partindo de um modelo **baseline** (Regressão Logística) e evoluindo para algoritmos mais avançados, como **ensembles** (Random Forest, AdaBoost) e **meta-modelos** (Voting Classifier). O objetivo é encontrar o equilíbrio ideal entre performance preditiva e complexidade do modelo.\n",
        "\n",
        "### Sobre o Dataset\n",
        "- **Origem**: Sintético, gerado com base em um modelo realista de processos de fresagem.\n",
        "- **Tamanho**: 10.000 registros e 14 variáveis.\n",
        "- **Referência**: S. Matzka, *Explainable Artificial Intelligence for Predictive Maintenance Applications*, AI4I 2020.\n",
        "\n",
        "### Variáveis Principais\n",
        "- **Variável Alvo (Target)**: `Machine Failure` (0 para \"Sem Falha\", 1 para \"Falha\").\n",
        "- **Principais Preditores (Features)**:\n",
        "    - `UID`: Identificador único da amostra.\n",
        "    - `Product ID`: Código do produto.\n",
        "    - `Type`: Categoria do produto (L, M, H = baixa, média, alta qualidade).\n",
        "    - `Air Temperature [K]`: Temperatura do ar no ambiente (em Kelvin).\n",
        "    - `Process Temperature [K]`: Temperatura do processo de usinagem (em Kelvin).\n",
        "    - `Rotational Speed [rpm]`: Velocidade de rotação da ferramenta (em rotações por minuto).\n",
        "    - `Torque [Nm]`: Torque aplicado pela ferramenta (em Newton-metros).\n",
        "    - `Tool Wear [min]`: Tempo de desgaste da ferramenta (em minutos).\n",
        "\n",
        "### Modos de Falha (Informativo)\n",
        "> O dataset também contém variáveis que indicam o tipo específico da falha, embora não sejam o alvo principal da nossa previsão binária.\n",
        "- **TWF**: Falha por Desgaste da Ferramenta (*Tool Wear Failure*).\n",
        "- **HDF**: Falha por Dissipação de Calor (*Heat Dissipation Failure*).\n",
        "- **PWF**: Falha por Perda de Potência (*Power Failure*).\n",
        "- **OSF**: Falha por Sobrecarga (*Overstrain Failure*).\n",
        "- **RNF**: Falha Aleatória (*Random Failure*).\n",
        "\n",
        "### Objetivo deste Milestone (Milestone 5)\n",
        "\n",
        "Este notebook cumpre os requisitos do quinto milestone do projeto. As etapas executadas aqui são:\n",
        "1.  **Treinamento de Modelos Avançados**: Implementação de múltiplos algoritmos que superam o baseline, utilizando técnicas de **ensemble** como `Random Forest`, `AdaBoost`, `Gradient Boosting` e `VotingClassifier`.\n",
        "2.  **Comparação de Desempenho**: Geração de uma **tabela comparativa** completa, avaliando todos os modelos com base nas métricas de F1-Score, Precisão e Recall.\n",
        "3.  **Documentação e Justificativa**: Utilização de células Markdown para explicar cada linha de código, as técnicas empregadas e para **interpretar os resultados** de forma crítica.\n",
        "4.  **Seleção do Modelo Final**: Análise da tabela de resultados para justificar a escolha do modelo campeão, considerando não apenas a performance (`Test F1-Score`), mas também o **custo-benefício** (`Complex Weight`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XGhnt6uUsZth",
      "metadata": {
        "id": "XGhnt6uUsZth"
      },
      "source": [
        "# 0.versionamento de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "OoIsdJ88rMDL",
      "metadata": {
        "id": "OoIsdJ88rMDL"
      },
      "outputs": [],
      "source": [
        "# utilizamos o google colab para desenvolver o codigo do trabalho,\n",
        "# intrução para rodar o notebook:\n",
        "# desconmentar os pip install abaixo e rodar as celulas abaixo dessa celula\n",
        "\n",
        "# !pip install matplotlib==3.10.6\n",
        "# !pip install pandas==2.3.2\n",
        "# !pip install scikit-learn==1.7.1\n",
        "# !pip install optuna==4.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72eb5822",
      "metadata": {
        "id": "72eb5822"
      },
      "source": [
        "# 1.import das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f8940ecb",
      "metadata": {
        "id": "f8940ecb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score\n",
        "\n",
        "# metodos proprios pra facilitar algumas etapas do trabalho\n",
        "def precision_recall_f1(y_true, y_probs, threshold=0.5):\n",
        "    y_pred = (y_probs >= threshold).astype(int)\n",
        "\n",
        "    precision = precision_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, pos_label=1, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"precision\": round(precision,5),\n",
        "        \"recall\": round(recall, 5),\n",
        "        \"f1\": round(f1, 5),\n",
        "    }\n",
        "\n",
        "def cv_metrics_precision_recall_f1(model, X, y, n_splits=5, random_state=42):\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "    precision_scorer = make_scorer(precision_score, pos_label=1)\n",
        "    recall_scorer = make_scorer(recall_score, pos_label=1)\n",
        "\n",
        "    scores_f1 = cross_val_score(model, X, y.values.ravel(), cv=skf, scoring=f1_scorer)\n",
        "    scores_precision = cross_val_score(model, X, y.values.ravel(), cv=skf, scoring=precision_scorer)\n",
        "    scores_recall = cross_val_score(model, X, y.values.ravel(), cv=skf, scoring=recall_scorer)\n",
        "\n",
        "    return {\n",
        "        'precision': float(round(scores_precision.mean(), 5)),\n",
        "        'recall': float(round(scores_recall.mean(), 5)),\n",
        "        'f1': float(round(scores_f1.mean(), 5))\n",
        "    }\n",
        "\n",
        "class ModelingExperiment:\n",
        "    def __init__(self):\n",
        "        self.records = []\n",
        "\n",
        "    def save(self, name, model=None, metrics=None, complex_weight=None):\n",
        "        print(\"model saved ...\", model)\n",
        "        self.records.append({\n",
        "            \"Model\": name,\n",
        "            \"Model Obj\": model,\n",
        "            \"Complex Weight\": complex_weight,\n",
        "            \"Model Params\": str(model) if model else None,\n",
        "            \"Train Precision\": metrics.get(\"train\", {}).get(\"precision\") if metrics else None,\n",
        "            \"Train Recall\": metrics.get(\"train\", {}).get(\"recall\") if metrics else None,\n",
        "            \"Train F1\": metrics.get(\"train\", {}).get(\"f1\") if metrics else None,\n",
        "            \"Validation Precision\": metrics.get(\"train\", {}).get(\"precision\") if metrics else None,\n",
        "            \"Validation Recall\": metrics.get(\"train\", {}).get(\"recall\") if metrics else None,\n",
        "            \"Validation F1\": metrics.get(\"train\", {}).get(\"f1\") if metrics else None,\n",
        "            \"Test Precision\": metrics.get(\"test\", {}).get(\"precision\") if metrics else None,\n",
        "            \"Test Recall\": metrics.get(\"test\", {}).get(\"recall\") if metrics else None,\n",
        "            \"Test F1\": metrics.get(\"test\", {}).get(\"f1\") if metrics else None\n",
        "        })\n",
        "\n",
        "    def summary(self, include_obj=False):\n",
        "        df = pd.DataFrame(self.records)\n",
        "        if not include_obj and \"Model Obj\" in df.columns:\n",
        "            df = df.drop(columns=[\"Model Obj\"])\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PlSmPbCfvN1h",
      "metadata": {
        "id": "PlSmPbCfvN1h"
      },
      "source": [
        "**Legenda:**  \n",
        "Nesta célula realizamos três etapas principais:\n",
        "\n",
        "1. **Importação de bibliotecas:**  \n",
        "   - `numpy`, `pandas`: manipulação de arrays e tabelas.  \n",
        "   - `seaborn`, `matplotlib.pyplot`: criação de gráficos e visualizações.  \n",
        "   - `pathlib.Path`, `tarfile`, `urllib.request`: operações com diretórios, arquivos compactados e downloads.  \n",
        "   - `sklearn.model_selection` e `sklearn.metrics`: ferramentas para validação cruzada e cálculo de métricas de classificação.  \n",
        "\n",
        "2. **Definição de funções auxiliares:**  \n",
        "   - `precision_recall_f1`: recebe os valores verdadeiros e as probabilidades previstas, aplica um limiar de decisão (`threshold`) e retorna **precisão, recall e F1-score** em formato de dicionário.  \n",
        "   - `cv_metrics_precision_recall_f1`: aplica **validação cruzada estratificada** em um modelo, calculando médias de precisão, recall e F1-score ao longo das divisões dos dados.  \n",
        "\n",
        "3. **Criação da classe `ModelingExperiment`:**  \n",
        "   - Armazena informações sobre cada modelo treinado, incluindo nome, parâmetros e métricas em treino, validação e teste.  \n",
        "   - O método `save` adiciona um registro na lista interna `records`.  \n",
        "   - O método `summary` organiza esses registros em um **DataFrame**, facilitando a comparação entre os modelos testados.  \n",
        "\n",
        " Em resumo, esta célula prepara o ambiente para os experimentos, fornecendo **ferramentas de avaliação de métricas** e uma **estrutura para registrar e comparar modelos**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e06e051",
      "metadata": {
        "id": "0e06e051"
      },
      "source": [
        "# 2.leitura da base de dados tratada milestone 3:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f6ba1055",
      "metadata": {
        "id": "f6ba1055"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    base_path = Path(\"datasets/industrial\")\n",
        "    base_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    url_base = \"https://raw.githubusercontent.com/bpriantti/av2_grupo_b_vespertino/main/\"\n",
        "\n",
        "    files = {\n",
        "        \"x_train\": base_path / \"x_train.csv\",\n",
        "        \"x_test\": base_path / \"x_test.csv\",\n",
        "        \"y_train\": base_path / \"y_train.csv\",\n",
        "        \"y_test\": base_path / \"y_test.csv\",\n",
        "    }\n",
        "\n",
        "    for name, path in files.items():\n",
        "        if not path.is_file():\n",
        "            urllib.request.urlretrieve(url_base + f\"{name}.csv\", path)\n",
        "\n",
        "    x_train = pd.read_csv(files[\"x_train\"])\n",
        "    x_test = pd.read_csv(files[\"x_test\"])\n",
        "    y_train = pd.read_csv(files[\"y_train\"])\n",
        "    y_test = pd.read_csv(files[\"y_test\"])\n",
        "\n",
        "    return x_train, x_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3dd98258",
      "metadata": {
        "id": "3dd98258"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "09feb834",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "09feb834",
        "outputId": "2b2ee359-e068-4298-a8cd-d4130890c3ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "x_train head():\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Type_ordinal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.146812</td>\n",
              "      <td>0.194985</td>\n",
              "      <td>3.424127</td>\n",
              "      <td>-2.323904</td>\n",
              "      <td>-1.190591</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.302583</td>\n",
              "      <td>-0.681839</td>\n",
              "      <td>1.444367</td>\n",
              "      <td>-1.572974</td>\n",
              "      <td>0.310316</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.552246</td>\n",
              "      <td>0.329881</td>\n",
              "      <td>0.559558</td>\n",
              "      <td>-1.082367</td>\n",
              "      <td>1.357824</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.801910</td>\n",
              "      <td>-0.681839</td>\n",
              "      <td>0.028673</td>\n",
              "      <td>-0.121176</td>\n",
              "      <td>-0.174352</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.345196</td>\n",
              "      <td>1.611391</td>\n",
              "      <td>-0.474562</td>\n",
              "      <td>0.729878</td>\n",
              "      <td>-0.721558</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
              "0             0.146812                 0.194985                3.424127   \n",
              "1            -0.302583                -0.681839                1.444367   \n",
              "2            -0.552246                 0.329881                0.559558   \n",
              "3            -0.801910                -0.681839                0.028673   \n",
              "4             1.345196                 1.611391               -0.474562   \n",
              "\n",
              "   Torque [Nm]  Tool wear [min]  Type_ordinal  \n",
              "0    -2.323904        -1.190591           1.0  \n",
              "1    -1.572974         0.310316           1.0  \n",
              "2    -1.082367         1.357824           1.0  \n",
              "3    -0.121176        -0.174352           2.0  \n",
              "4     0.729878        -0.721558           1.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train head():\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Machine failure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Machine failure\n",
              "0                0\n",
              "1                0\n",
              "2                0\n",
              "3                0\n",
              "4                0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_test head():\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Air temperature [K]</th>\n",
              "      <th>Process temperature [K]</th>\n",
              "      <th>Rotational speed [rpm]</th>\n",
              "      <th>Torque [Nm]</th>\n",
              "      <th>Tool wear [min]</th>\n",
              "      <th>Type_ordinal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.751977</td>\n",
              "      <td>-0.209703</td>\n",
              "      <td>0.072913</td>\n",
              "      <td>-0.601771</td>\n",
              "      <td>1.514169</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.401102</td>\n",
              "      <td>-0.951630</td>\n",
              "      <td>-0.811895</td>\n",
              "      <td>0.149159</td>\n",
              "      <td>-0.002373</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.246677</td>\n",
              "      <td>1.274152</td>\n",
              "      <td>-0.590693</td>\n",
              "      <td>0.309357</td>\n",
              "      <td>-1.440742</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.644793</td>\n",
              "      <td>1.476496</td>\n",
              "      <td>-0.452442</td>\n",
              "      <td>0.069060</td>\n",
              "      <td>-0.940440</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.052919</td>\n",
              "      <td>-0.412047</td>\n",
              "      <td>1.936542</td>\n",
              "      <td>-1.402764</td>\n",
              "      <td>-1.597087</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
              "0            -0.751977                -0.209703                0.072913   \n",
              "1            -1.401102                -0.951630               -0.811895   \n",
              "2             0.246677                 1.274152               -0.590693   \n",
              "3             1.644793                 1.476496               -0.452442   \n",
              "4            -0.052919                -0.412047                1.936542   \n",
              "\n",
              "   Torque [Nm]  Tool wear [min]  Type_ordinal  \n",
              "0    -0.601771         1.514169           2.0  \n",
              "1     0.149159        -0.002373           1.0  \n",
              "2     0.309357        -1.440742           1.0  \n",
              "3     0.069060        -0.940440           1.0  \n",
              "4    -1.402764        -1.597087           2.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_test head():\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Machine failure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Machine failure\n",
              "0                0\n",
              "1                0\n",
              "2                0\n",
              "3                0\n",
              "4                0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"\")\n",
        "print(\"x_train head():\")\n",
        "display(x_train.head())\n",
        "print(\"y_train head():\")\n",
        "display(y_train.head())\n",
        "print(\"x_test head():\")\n",
        "display(x_test.head())\n",
        "print(\"y_test head():\")\n",
        "display(y_test.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e521508d",
      "metadata": {
        "id": "e521508d"
      },
      "source": [
        "**Legenda:**  \n",
        "\n",
        "#### Função `load_data`\n",
        "Esta célula define a função `load_data`, responsável por **carregar e organizar os dados do projeto**:\n",
        "Aqui a função load_data é chamada e suas saídas são atribuídas às variáveis de treino e teste.\n",
        "\n",
        "    1.`x_train`, `x_test`: atributos (features) normalizados já preparados.\n",
        "\n",
        "    2. `y_train`, `y_test`.: rótulos (targets) binários indicando falha ou não da máquina.\n",
        "\n",
        "Essa função inicializa efetivamente os dados que serão usados em todo o restante do notebook.\n",
        "\n",
        "---\n",
        "\n",
        "#### Carregamento dos dados\n",
        "```python\n",
        "x_train, x_test, y_train, y_test = load_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3fd2663",
      "metadata": {
        "id": "c3fd2663"
      },
      "source": [
        "# 3.0 Treinamento dos modelos:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6a7cdb",
      "metadata": {
        "id": "3a6a7cdb"
      },
      "source": [
        ">Nesta etapa, vamos explorar diferentes algoritmos de **Machine Learning** para prever falhas em máquinas de usinagem.  \n",
        "O foco é avaliar o desempenho na **classe 1 (falha)** utilizando métricas como **Precision, Recall e F1-Score**.\n",
        "\n",
        "Modelos a serem testados:\n",
        "1. **Logistic Regression** `(Baseline)`\n",
        "2. **Support Vector Machine**  \n",
        "3. **Decision Tree**  \n",
        "4. **Random Forest**  \n",
        "5. **AdaBoost**  \n",
        "6. **Gradient Boosting**    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4-QlhGAK22D1",
      "metadata": {
        "id": "4-QlhGAK22D1"
      },
      "source": [
        "\n",
        "#### Atribuição de Peso de Complexidade para Cada Modelo:\n",
        "\n",
        "1.  **Logistic Regression (peso 1):**\n",
        "    * Modelo mais simples, linear, ótimo como baseline.\n",
        "\n",
        "2.  **Decision Tree (peso 2):**\n",
        "    * Já captura relações não lineares, mas isoladamente tende a *overfitting* (sobresjuste).\n",
        "\n",
        "3.  **Support Vector Machine (peso 3):**\n",
        "    * Bom em problemas com margens de separação claras, mas exige ajuste fino (*tuning*) do kernel e não escala bem em grandes volumes de dados.\n",
        "\n",
        "4.  **Random Forest (peso 4):**\n",
        "    * Mais robusto que uma única árvore de decisão, pois é um conjunto (*ensemble*) delas. Reduz o *overfitting* e generaliza melhor.\n",
        "\n",
        "5.  **AdaBoost (peso 5):**\n",
        "    * Constrói um *ensemble* de forma sequencial, onde cada novo modelo foca em corrigir os erros do modelo anterior. É eficaz em dados com pouco ruído, mas pode ser sensível a *outliers* (valores atípicos).\n",
        "\n",
        "6.  **Gradient Boosting (peso 6):**\n",
        "    * Semelhante ao AdaBoost, também constrói modelos sequencialmente. No entanto, é mais flexível e poderoso, pois otimiza os erros residuais a cada passo usando um método de gradiente. Geralmente, apresenta um desempenho superior aos anteriores.\n",
        "\n",
        "7.  **Voting Classifier (peso 7):**\n",
        "    * É um meta-modelo que combina as previsões de vários modelos diferentes (por exemplo, Regressão Logística, SVM e Random Forest). A previsão final é decidida pela \"votação\" da maioria dos modelos (*hard voting*) ou pela média das probabilidades previstas por eles (*soft voting*). Sua principal vantagem é aumentar a robustez e a precisão ao agregar as \"opiniões\" de diferentes algoritmos, compensando as fraquezas individuais de cada um."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2b692120",
      "metadata": {
        "id": "2b692120"
      },
      "outputs": [],
      "source": [
        "experimento = ModelingExperiment()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f44d5cf1",
      "metadata": {
        "id": "f44d5cf1"
      },
      "source": [
        "## 3.1 logistic regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5838b0b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "5838b0b4",
        "outputId": "420ff2fe-5df9-4a7e-b514-bce16cdff967"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': {'precision': 0.58042, 'recall': 0.31439, 'f1': 0.40786},\n",
              " 'val': {'precision': 0.56741, 'recall': 0.3029, 'f1': 0.39385},\n",
              " 'test': {'precision': 0.69444, 'recall': 0.37879, 'f1': 0.4902}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# log_reg = LogisticRegression(class_weight={0:1, 1:2}, random_state=42)\n",
        "# log_reg.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# y_train_probs = log_reg.predict_proba(x_train)[:, 1]\n",
        "# y_test_probs = log_reg.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "# metrics_val = cv_metrics_precision_recall_f1(log_reg, x_train, y_train, n_splits=5, random_state=42)\n",
        "# metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "\n",
        "# metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "# display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "821fc0b7",
      "metadata": {
        "id": "821fc0b7"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula estamos treinando um modelo de **Regressão Logística** usando a biblioteca *scikit-learn*. Algumas observações importantes:\n",
        "\n",
        "### Configuração do modelo\n",
        "- `class_weight={0:1, 1:2}`: estamos dizendo ao modelo para dar o **dobro de peso à classe 1** em relação à classe 0.  \n",
        "  Isso é útil quando há **desbalanceamento de classes**, pois força o algoritmo a prestar mais atenção à classe minoritária.  \n",
        "- `random_state=42`: garante **reprodutibilidade**, ou seja, os mesmos resultados em execuções diferentes.  \n",
        "\n",
        "---\n",
        "\n",
        "### Treinamento (`fit`)\n",
        "- O modelo aprende padrões nos dados de treino (`x_train`, `y_train`).  \n",
        "\n",
        "---\n",
        "\n",
        "### Probabilidades previstas (`predict_proba`)\n",
        "- Calculamos a probabilidade de cada instância pertencer à classe **1**, tanto no treino quanto no teste.  \n",
        "- Depois, avaliamos o modelo usando a função `evaluate_model`, com um **limiar (threshold) de 0.5**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Métricas obtidas\n",
        "**Treino:**\n",
        "- **Precisão ≈ 0.58** → quando o modelo prevê a classe positiva, ele acerta em ~58% dos casos.  \n",
        "- **Recall ≈ 0.31** → o modelo consegue recuperar apenas ~31% dos positivos reais (**sensibilidade baixa**).  \n",
        "- **F1-score ≈ 0.40** → equilíbrio baixo, indicando que o modelo não está performando tão bem no treino.  \n",
        "\n",
        "**Teste:**\n",
        "- **Precisão ≈ 0.69** → acerta mais quando prevê positivo (~69%).  \n",
        "- **Recall ≈ 0.37** → ainda captura poucos positivos (~37%).  \n",
        "- **F1-score ≈ 0.49** → melhora em relação ao treino, mas ainda mostra que o modelo não está capturando bem os positivos.  \n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação geral\n",
        "- O modelo tem uma **precisão razoável**, mas um **recall baixo**.  \n",
        "- Isso significa que ele **erra ao deixar escapar muitos casos positivos** (alta taxa de **falsos negativos**).  \n",
        "- Como consequência, o **F1-score** fica moderado (~0.49), sugerindo que o modelo ainda **não está bem ajustado** e pode precisar de:  \n",
        "  - Ajuste do **limiar de decisão**.  \n",
        "  - Melhor balanceamento de classes.  \n",
        "  - Testar outros modelos ou adicionar novas features.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2044f60",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2044f60",
        "outputId": "e703743a-0f70-4490-c98d-fec9fd2e28a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved ... LogisticRegression(class_weight={0: 1, 1: 2}, random_state=42)\n"
          ]
        }
      ],
      "source": [
        "# experimento.save(name=\"Logistic Regression\", model=log_reg, metrics=metrics, complex_weight=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d5302c4",
      "metadata": {
        "id": "9d5302c4"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "> Nesta célula, o código utiliza o método `save` do objeto `experimento` para armazenar o modelo treinado e suas informações principais:\n",
        ">\n",
        "> -   `name=\"Logistic Regression\"` → Identifica o modelo salvo com o nome \"Logistic Regression\".\n",
        "> -   `model=log_reg` → Refere-se ao modelo de Regressão Logística que já foi treinado e agora será registrado.\n",
        "> -   `metrics=metrics` → Inclui as métricas de avaliação calculadas (ex.: acurácia, F1-score, recall etc.) junto ao modelo.\n",
        "> -   `complex_weight=1` → Define um peso de complexidade para o modelo, usado em comparações ou análises de custo/benefício.\n",
        "\n",
        "**Em resumo**, essa linha registra o modelo e suas métricas dentro do sistema de experimentos, permitindo organização e reprodutibilidade."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af68a4a0",
      "metadata": {
        "id": "af68a4a0"
      },
      "source": [
        "## 3.2 SVM classifier:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6a6e616",
      "metadata": {
        "id": "c6a6e616"
      },
      "source": [
        "### 3.2.1 fine tunning parameter config SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "36ed0c32",
      "metadata": {
        "id": "36ed0c32"
      },
      "outputs": [],
      "source": [
        "# # comentamos pois ja encontramos os parametros - tempo de execucao aproximadamente: 41 minutos\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "# from sklearn.metrics import make_scorer, f1_score\n",
        "# from sklearn.svm import SVC\n",
        "# import optuna\n",
        "\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "# def objective(trial):\n",
        "#     C = trial.suggest_float(\"C\", 0.1, 100, log=True)\n",
        "#     weight_1 = trial.suggest_int(\"weight_1\", 1, 10)\n",
        "\n",
        "#     svm_model = SVC(\n",
        "#         C=C,\n",
        "#         class_weight={0:1, 1:weight_1},\n",
        "#         probability=True,\n",
        "#         random_state=42,\n",
        "#     )\n",
        "\n",
        "#     scores = cross_val_score(svm_model, x_train, y_train.values.ravel(), cv=skf, scoring=f1_scorer)\n",
        "#     return scores.mean()\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(objective, n_trials=1000)\n",
        "# print(\"Melhores parâmetros:\", study.best_trial.params)\n",
        "# print(\"Melhor F1 médio na validação:\", study.best_trial.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd94ac79",
      "metadata": {
        "id": "dd94ac79"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula foi realizada a **otimização de hiperparâmetros da SVM** utilizando a biblioteca **Optuna**, com o objetivo de encontrar uma configuração de parâmetros que maximize o desempenho do modelo em termos de **F1-score**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Parâmetros otimizados\n",
        "- **`C` (regularização):** controla o equilíbrio entre **margem larga** e **classificação correta dos exemplos de treino**.  \n",
        "  - Valores menores de `C` → permitem maior margem, mas aceitam mais erros no treino (modelo mais simples, com maior viés).  \n",
        "  - Valores maiores de `C` → buscam classificar todos os exemplos corretamente, mesmo reduzindo a margem (modelo mais complexo, com risco de overfitting).  \n",
        "\n",
        "- **`class_weight` (peso das classes):** aqui ajustamos o peso da **classe positiva (1)**.  \n",
        "  - Isso é importante porque, em problemas de **desbalanceamento de classes**, o modelo tende a favorecer a classe majoritária.  \n",
        "  - Ajustando o peso da classe 1, forçamos a SVM a dar **mais atenção às instâncias positivas**, ajudando a melhorar o **recall** e, consequentemente, o **F1-score**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Estratégia de validação\n",
        "- Foi utilizada **validação cruzada estratificada (5 folds)** para garantir que cada divisão tivesse a mesma proporção de classes, evitando viés nos resultados.  \n",
        "- O critério de avaliação foi o **F1-score**, métrica que equilibra precisão e recall, escolhida porque o dataset provavelmente apresenta **desbalanceamento** entre classes.  \n",
        "\n",
        "---\n",
        "\n",
        "### Processo de otimização\n",
        "- A função `objective(trial)` define como cada experimento de treinamento deve ser avaliado, recebendo diferentes combinações de `C` e `weight_1`.  \n",
        "- O Optuna testou até **1000 combinações** desses hiperparâmetros.  \n",
        "- Ao final, o estudo retornou:  \n",
        "  - **Melhores parâmetros encontrados** (valores de `C` e `class_weight`).  \n",
        "  - **Melhor valor médio de F1-score na validação cruzada**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa\n",
        "Optamos por realizar esta otimização porque a SVM é **sensível à escolha dos hiperparâmetros**, especialmente:  \n",
        "- O valor de `C`, que influencia diretamente a complexidade do modelo.  \n",
        "- O peso das classes, que pode corrigir o impacto do desbalanceamento.  \n",
        "\n",
        "Dessa forma, garantimos que o modelo utilizado nas próximas etapas **não seja apenas uma configuração arbitrária**, mas sim o resultado de um processo sistemático de busca, visando **equilíbrio entre precisão e recall**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3efb8552",
      "metadata": {
        "id": "3efb8552"
      },
      "source": [
        "### 3.2.2 fit best parameter config SVM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ca1575",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "e4ca1575",
        "outputId": "dfd667b0-b3bc-42e2-afbb-d0276950fc2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': {'precision': 0.97525, 'recall': 0.74621, 'f1': 0.84549},\n",
              " 'val': {'precision': 0.82832, 'recall': 0.66676, 'f1': 0.73733},\n",
              " 'test': {'precision': 0.84091, 'recall': 0.56061, 'f1': 0.67273}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from sklearn.svm import SVC\n",
        "\n",
        "# svm_model = SVC(\n",
        "#         C=99.90622647684818,\n",
        "#         class_weight={0:1, 1:1},\n",
        "#         probability=True,\n",
        "#         random_state=42,\n",
        "#     )\n",
        "\n",
        "\n",
        "# svm_model.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# y_train_probs = svm_model.predict_proba(x_train)[:, 1]\n",
        "# y_test_probs = svm_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "# metrics_val = cv_metrics_precision_recall_f1(svm_model, x_train, y_train, n_splits=5, random_state=42)\n",
        "# metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "# metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "# display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d62168d0",
      "metadata": {
        "id": "d62168d0"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula estamos treinando um modelo de **SVM (Support Vector Machine)** usando a classe `SVC` da biblioteca *scikit-learn*. Algumas observações importantes:\n",
        "\n",
        "---\n",
        "\n",
        "### Configuração do modelo\n",
        "- `C=99.9062`: parâmetro de **regularização** que controla a margem da SVM.  \n",
        "- `class_weight={0:1, 1:1}`: indica que **não foi aplicado balanceamento de classes** (ambas têm o mesmo peso).  \n",
        "- `probability=True`: habilita a saída de **probabilidades** via `predict_proba`.  \n",
        "- `random_state=42`: garante **reprodutibilidade** dos resultados.  \n",
        "\n",
        "---\n",
        "\n",
        "### Treinamento (`fit`)\n",
        "- O modelo é treinado com os dados de entrada (`x_train`) e os rótulos (`y_train`).  \n",
        "- A SVM busca encontrar um **hiperplano ótimo** que separe as classes no espaço das features.  \n",
        "\n",
        "---\n",
        "\n",
        "### Probabilidades previstas (`predict_proba`)\n",
        "- Após o treinamento, calculamos as **probabilidades da classe positiva (1)** para:  \n",
        "  - **Treino:** `y_train_probs`  \n",
        "  - **Teste:** `y_test_probs`  \n",
        "- Essas probabilidades são avaliadas com um **limiar (threshold) = 0.5**, transformando-as em previsões binárias.  \n",
        "\n",
        "---\n",
        "\n",
        "### Métricas obtidas\n",
        "**Treino:**  \n",
        "- **Precisão ≈ 0.98** → quando o modelo prevê positivo, acerta quase sempre.  \n",
        "- **Recall ≈ 0.75** → captura cerca de 75% dos casos positivos.  \n",
        "- **F1-score ≈ 0.85** → bom equilíbrio entre precisão e recall no treino.  \n",
        "\n",
        "**Validação cruzada (5 folds):**  \n",
        "- **Precisão ≈ 0.83** → boa taxa de acerto nas previsões positivas.  \n",
        "- **Recall ≈ 0.67** → captura 67% dos positivos, um pouco menor que no treino.  \n",
        "- **F1-score ≈ 0.74** → desempenho consistente, indicando que o modelo generaliza razoavelmente bem.  \n",
        "\n",
        "**Teste:**  \n",
        "- **Precisão ≈ 0.84** → mantém boa taxa de acertos ao prever positivos.  \n",
        "- **Recall ≈ 0.56** → consegue capturar pouco mais da metade dos casos positivos.  \n",
        "- **F1-score ≈ 0.67** → equilíbrio moderado, inferior ao treino, mas dentro do esperado.  \n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação geral\n",
        "- O modelo de **SVM apresenta excelente precisão**, ou seja, quase nunca erra ao prever a classe positiva.  \n",
        "- Porém, o **recall é mais baixo**, especialmente no teste (~0.56), mostrando que o modelo **deixa escapar muitos casos positivos** (falsos negativos).  \n",
        "- O **F1-score de ~0.67 no teste** indica desempenho aceitável, mas há espaço para melhoria.  \n",
        "\n",
        "Caminhos para evolução:  \n",
        "- **Ajustar o parâmetro `C`** para encontrar melhor equilíbrio entre precisão e recall.  \n",
        "- Testar **balanceamento de classes** (`class_weight=\"balanced\"`) para melhorar o recall.  \n",
        "- Avaliar outros kernels da SVM (linear, polinomial, RBF) para ver se melhoram a separação das classes.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T35WI8d7072U",
      "metadata": {
        "id": "T35WI8d7072U"
      },
      "source": [
        "foi treinado o melhor modelo com os melhores parametros obtidos na otimizacao, fala um pouco das metricas resumidamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64db861b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64db861b",
        "outputId": "12a45011-4786-4e4e-b13e-c8cfd9cf4e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved ... SVC(C=99.90622647684818, class_weight={0: 1, 1: 1}, probability=True,\n",
            "    random_state=42)\n"
          ]
        }
      ],
      "source": [
        "# experimento.save(name=\"Support Vector Classifier\", model=svm_model, metrics=metrics, complex_weight=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38f13163",
      "metadata": {
        "id": "38f13163"
      },
      "source": [
        "> Nesta célula, o método `save` do objeto `experimento` é usado para armazenar o modelo de classificação SVM (Support Vector Classifier) junto às suas métricas de desempenho. Os parâmetros têm os seguintes papéis:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f41f2ef",
      "metadata": {
        "id": "0f41f2ef"
      },
      "source": [
        "## 3.3 decision tree classifier:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfde426f",
      "metadata": {
        "id": "dfde426f"
      },
      "source": [
        "### 3.3.1 fine tunning decision tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "67865a81",
      "metadata": {
        "id": "67865a81"
      },
      "outputs": [],
      "source": [
        "# # comentamos pois ja encontramos os parametros - tempo de execucao aproximadamente: 19 minutos\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "# from sklearn.metrics import make_scorer, f1_score\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# import optuna\n",
        "\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "# def objective(trial):\n",
        "#     max_depth = trial.suggest_categorical(\"max_depth\", [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21])\n",
        "#     min_samples_leaf = trial.suggest_categorical(\"min_samples_leaf\", [2, 3, 5, 7, 9])\n",
        "#     min_samples_split = trial.suggest_categorical(\"min_samples_split\", [2, 3, 5, 7, 9])\n",
        "#     min_impurity_decrease = trial.suggest_categorical(\"min_impurity_decrease\", [0.0, 0.01, 0.001, 0.0001])\n",
        "#     weight_1 = trial.suggest_int(\"weight_1\", 1, 10)\n",
        "\n",
        "#     tree = DecisionTreeClassifier(\n",
        "#                                     max_depth=max_depth,\n",
        "#                                     min_samples_leaf=min_samples_leaf,\n",
        "#                                     min_samples_split=min_samples_split,\n",
        "#                                     min_impurity_decrease=min_impurity_decrease,\n",
        "#                                     class_weight={0: 1, 1: weight_1},\n",
        "#                                     random_state=42\n",
        "#                                 )\n",
        "\n",
        "#     scores = cross_val_score(tree, x_train, y_train.values.ravel(), cv=skf, scoring=f1_scorer)\n",
        "#     return scores.mean()\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(objective, n_trials=1000)\n",
        "\n",
        "# print(\"Melhores parâmetros:\", study.best_trial.params)\n",
        "# print(\"Melhor F1 médio na validação:\", study.best_trial.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc64c76",
      "metadata": {
        "id": "bfc64c76"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula foi realizada a **otimização dos hiperparâmetros de uma Árvore de Decisão** utilizando a biblioteca **Optuna**, com foco em maximizar o **F1-score**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Parâmetros otimizados\n",
        "- **`max_depth`**: profundidade máxima da árvore. Controla a complexidade; valores muito altos podem levar a overfitting.  \n",
        "- **`min_samples_leaf`**: número mínimo de amostras em cada folha; evita folhas com poucos exemplos.  \n",
        "- **`min_samples_split`**: número mínimo de amostras necessárias para realizar uma divisão; controla a fragmentação da árvore.  \n",
        "- **`min_impurity_decrease`**: limite mínimo de redução de impureza para permitir uma divisão; ajuda a podar splits irrelevantes.  \n",
        "- **`class_weight`**: ajusta o peso da classe positiva (1). Essencial em datasets desbalanceados, pois aumenta a importância das falhas (classe minoritária).  \n",
        "\n",
        "---\n",
        "\n",
        "### Estratégia de validação\n",
        "- Utilizou-se **validação cruzada estratificada (5 folds)** para manter as proporções de classes em cada divisão.  \n",
        "- A métrica usada foi o **F1-score**, ideal em cenários onde há **desbalanceamento de classes**, pois equilibra precisão e recall.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa\n",
        "Optamos por otimizar porque árvores de decisão são altamente sensíveis à escolha de hiperparâmetros.  \n",
        "Sem esse ajuste, o modelo poderia ficar **muito simples (alto viés)** ou **muito complexo (alto overfitting)**.  \n",
        "\n",
        "Assim, a otimização garantiu um modelo melhor balanceado, capaz de capturar falhas sem comprometer demais a precisão.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d79ed347",
      "metadata": {
        "id": "d79ed347"
      },
      "source": [
        "### 3.3.2 fit best parameter config decision tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8631b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "8a8631b1",
        "outputId": "1779b0d8-4a63-4642-a935-e3889f177f0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': {'precision': 0.86585, 'recall': 0.80682, 'f1': 0.83529},\n",
              " 'val': {'precision': 0.8398, 'recall': 0.62104, 'f1': 0.71341},\n",
              " 'test': {'precision': 0.79688, 'recall': 0.77273, 'f1': 0.78462}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# tree_model = DecisionTreeClassifier(\n",
        "#                                 max_depth=11,\n",
        "#                                 min_samples_leaf=5,\n",
        "#                                 min_samples_split=2,\n",
        "#                                 min_impurity_decrease=0.0001,\n",
        "#                                 class_weight={0: 1, 1: 1},\n",
        "#                                 random_state=42\n",
        "#                             )\n",
        "\n",
        "# tree_model.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# y_train_probs = tree_model.predict_proba(x_train)[:, 1]\n",
        "# y_test_probs = tree_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "# metrics_val = cv_metrics_precision_recall_f1(tree_model, x_train, y_train, n_splits=5, random_state=42)\n",
        "# metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "# metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "# display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b488ebf4",
      "metadata": {
        "id": "b488ebf4"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula treinamos uma **Árvore de Decisão** já configurada com os melhores parâmetros encontrados na otimização anterior.  \n",
        "\n",
        "### Configuração do modelo\n",
        "- `max_depth=11`: profundidade máxima da árvore, evitando overfitting excessivo.  \n",
        "- `min_samples_leaf=5`: cada folha deve ter pelo menos 5 amostras, aumentando a robustez.  \n",
        "- `min_samples_split=2`: divisão mínima permitida de nós.  \n",
        "- `min_impurity_decrease=0.0001`: só permite splits que tragam ganho mínimo de pureza.  \n",
        "- `class_weight={0:1, 1:1}`: não aplicamos pesos diferenciados nesta versão final.  \n",
        "- `random_state=42`: garante reprodutibilidade.  \n",
        "\n",
        "---\n",
        "\n",
        "### Treinamento e avaliação\n",
        "- O modelo foi treinado em `x_train, y_train`.  \n",
        "- As probabilidades previstas foram avaliadas tanto no **treino**, **validação cruzada** e **teste**.  \n",
        "- Utilizamos `precision_recall_f1` e `cv_metrics_precision_recall_f1` para calcular as métricas principais.  \n",
        "\n",
        "---\n",
        "\n",
        "### Métricas obtidas\n",
        "**Treino:**  \n",
        "- Precisão ≈ **0.87**  \n",
        "- Recall ≈ **0.81**  \n",
        "- F1 ≈ **0.84**  \n",
        "\n",
        "**Validação cruzada (5 folds):**  \n",
        "- Precisão ≈ **0.84**  \n",
        "- Recall ≈ **0.62**  \n",
        "- F1 ≈ **0.71**  \n",
        "\n",
        "**Teste:**  \n",
        "- Precisão ≈ **0.80**  \n",
        "- Recall ≈ **0.77**  \n",
        "- F1 ≈ **0.78**  \n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação geral\n",
        "- O modelo apresenta **bom equilíbrio entre precisão e recall**, especialmente no teste, com **F1 ≈ 0.78**.  \n",
        "- A precisão está alta (~0.80), o que significa poucas previsões falsas de falha.  \n",
        "- O recall também é consistente (~0.77), mostrando que o modelo recupera a maior parte das falhas reais.  \n",
        "- Comparado a modelos anteriores, a Árvore de Decisão mostra-se **mais equilibrada** e com **melhor recall**, o que é positivo em um problema de predição de falhas.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb6b8e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecb6b8e2",
        "outputId": "6fc69de2-de73-4855-f6fb-116b5f2e851a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved ... DecisionTreeClassifier(class_weight={0: 1, 1: 1}, max_depth=11,\n",
            "                       min_impurity_decrease=0.0001, min_samples_leaf=5,\n",
            "                       random_state=42)\n"
          ]
        }
      ],
      "source": [
        "# experimento.save(name=\"Decision Tree Classifier\", model=tree_model, metrics=metrics, complex_weight=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bba8faf",
      "metadata": {
        "id": "4bba8faf"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "> Esta linha de código utiliza o método `save` do objeto `experimento` para registrar o modelo de Árvore de Decisão (`Decision Tree`) que foi treinado.\n",
        ">**Em resumo**, o código salva o modelo de Árvore de Decisão, seu nome, suas métricas de performance e seu peso de complexidade no sistema de experimentação.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f344d299",
      "metadata": {
        "id": "f344d299"
      },
      "source": [
        "## 3.4 random forrest:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbe69c66",
      "metadata": {
        "id": "dbe69c66"
      },
      "source": [
        "##### 3.4.1 fine tunning random forrest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee34e22c",
      "metadata": {
        "id": "ee34e22c"
      },
      "outputs": [],
      "source": [
        "# cometamos pois ja encontramos os parametros, descomentar caso queria rodar novamente - tempo de execucao aproximadamente: 325 minutos\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import optuna\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "def objective(trial):\n",
        "    max_depth = trial.suggest_categorical(\"max_depth\", [5, 10, 15, 20, 30, 40, 50])\n",
        "    min_samples_leaf = trial.suggest_categorical(\"min_samples_leaf\", [2, 3, 4, 5])\n",
        "    min_samples_split = trial.suggest_categorical(\"min_samples_split\", [2, 3, 4, 5])\n",
        "    weight_1 = trial.suggest_categorical(\"weight_1\", [1, 2, 3, 4, 5, 6, 7, 8, 9,10])\n",
        "    min_impurity_decrease = trial.suggest_categorical(\"min_impurity_decrease\", [0.0, 0.01, 0.001, 0.0001])\n",
        "    max_features = trial.suggest_categorical(\"max_features\", [0.5, 0.7, 1.0, \"sqrt\", \"log2\"])\n",
        "    criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"])\n",
        "    n_estimators = trial.suggest_categorical(\"n_estimators\", [10, 50, 100, 200, 300, 500])\n",
        "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
        "\n",
        "\n",
        "    rf_model = RandomForestClassifier(\n",
        "            max_depth=max_depth,\n",
        "            n_estimators=n_estimators,\n",
        "            min_samples_leaf=min_samples_leaf,\n",
        "            min_samples_split=min_samples_split,\n",
        "            class_weight={0:1, 1:weight_1},\n",
        "            min_impurity_decrease=min_impurity_decrease,\n",
        "            max_features=max_features,\n",
        "            criterion=criterion,\n",
        "            bootstrap=bootstrap,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    scores = cross_val_score(rf_model, x_train, y_train.values.ravel(), cv=skf, scoring=f1_scorer)\n",
        "    return scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=1000)\n",
        "\n",
        "print(\"Melhores parâmetros:\", study.best_trial.params)\n",
        "print(\"Melhor F1 médio na validação:\", study.best_trial.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264459dd",
      "metadata": {
        "id": "264459dd"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula realizamos a **otimização de hiperparâmetros de uma Random Forest**, com o objetivo de maximizar o **F1-score**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Parâmetros otimizados\n",
        "- **`max_depth`**: profundidade máxima das árvores. Controla o equilíbrio entre simplicidade e complexidade do modelo.  \n",
        "- **`min_samples_leaf`**: número mínimo de amostras em cada folha, evita divisões muito pequenas.  \n",
        "- **`min_samples_split`**: número mínimo de amostras para que um nó seja dividido.  \n",
        "- **`class_weight`**: ajusta o peso da classe positiva (1), essencial em datasets desbalanceados.  \n",
        "- **`min_impurity_decrease`**: define a redução mínima de impureza para aceitar uma divisão.  \n",
        "- **`max_features`**: número de variáveis consideradas em cada divisão (`0.5`, `0.7`, `1.0`, `\"sqrt\"`, `\"log2\"`). Controla a diversidade das árvores.  \n",
        "- **`criterion`**: medida usada para avaliar divisões (impureza de **Gini** ou **Entropia**).  \n",
        "- **`n_estimators`**: número de árvores no ensemble. Mais árvores aumentam estabilidade, mas também custo computacional.  \n",
        "- **`bootstrap`**: se `True`, cada árvore é treinada em uma amostra bootstrap (com reposição), promovendo diversidade.  \n",
        "\n",
        "---\n",
        "\n",
        "### Estratégia de validação\n",
        "- Utilizamos **validação cruzada estratificada (5 folds)** para manter a proporção das classes.  \n",
        "- Métrica: **F1-score**, escolhida por equilibrar precisão e recall em um problema com **desbalanceamento de classes**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa\n",
        "A Random Forest possui diversos hiperparâmetros que impactam diretamente no desempenho.  \n",
        "Optar por otimização sistemática evita escolhas arbitrárias e garante um modelo **mais robusto e equilibrado**.  \n",
        "\n",
        "Com isso, conseguimos encontrar uma configuração de floresta que maximiza o **F1-score**, capturando mais falhas sem perder muita precisão.  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2a9e8ac",
      "metadata": {
        "id": "d2a9e8ac"
      },
      "source": [
        "### 3.4.2 fit best parameter config Random Forrest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bdd27d98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "bdd27d98",
        "outputId": "72320130-12e8-4675-de96-20795e01a6de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': {'precision': 0.94928, 'recall': 0.99242, 'f1': 0.97037},\n",
              " 'val': {'precision': 0.8736, 'recall': 0.73091, 'f1': 0.79472},\n",
              " 'test': {'precision': 0.9, 'recall': 0.81818, 'f1': 0.85714}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(max_depth=15,\n",
        "                                  n_estimators=500,\n",
        "                                  min_samples_leaf=3,\n",
        "                                  min_samples_split=3,\n",
        "                                  class_weight={0:1, 1:7},\n",
        "                                  min_impurity_decrease=0.0,\n",
        "                                  max_features=0.7,\n",
        "                                  criterion=\"entropy\",\n",
        "                                  bootstrap=True,\n",
        "                                  random_state=42,\n",
        "                                )\n",
        "\n",
        "rf_model.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "y_train_probs = rf_model.predict_proba(x_train)[:, 1]\n",
        "y_test_probs = rf_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "metrics_val = cv_metrics_precision_recall_f1(rf_model, x_train, y_train, n_splits=5, random_state=42)\n",
        "metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67dfc108",
      "metadata": {
        "id": "67dfc108"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula treinamos o modelo **Random Forest** utilizando os parâmetros encontrados na otimização.  \n",
        "\n",
        "### Configuração do modelo\n",
        "- `max_depth=15`: controla a profundidade máxima das árvores, limitando complexidade.  \n",
        "- `n_estimators=500`: usa 500 árvores, garantindo **alta estabilidade**.  \n",
        "- `min_samples_leaf=3`: cada folha deve ter pelo menos 3 amostras.  \n",
        "- `min_samples_split=3`: exige ao menos 3 amostras para dividir um nó.  \n",
        "- `class_weight={0:1, 1:7}`: aumenta o peso da classe positiva, forçando o modelo a dar mais atenção às falhas.  \n",
        "- `min_impurity_decrease=0.0`: sem exigência mínima de ganho de pureza.  \n",
        "- `max_features=0.7`: cada árvore considera apenas 70% das variáveis em cada split, aumentando diversidade.  \n",
        "- `criterion=\"entropy\"`: usa entropia para medir qualidade das divisões.  \n",
        "- `bootstrap=True`: usa amostras bootstrap para cada árvore.  \n",
        "- `random_state=42`: garante reprodutibilidade.  \n",
        "\n",
        "---\n",
        "\n",
        "### Métricas obtidas\n",
        "**Treino:**  \n",
        "- Precisão ≈ **0.95**  \n",
        "- Recall ≈ **0.99**  \n",
        "- F1 ≈ **0.97**  \n",
        "\n",
        "**Validação cruzada (5 folds):**  \n",
        "- Precisão ≈ **0.87**  \n",
        "- Recall ≈ **0.73**  \n",
        "- F1 ≈ **0.79**  \n",
        "\n",
        "**Teste:**  \n",
        "- Precisão ≈ **0.90**  \n",
        "- Recall ≈ **0.82**  \n",
        "- F1 ≈ **0.86**  \n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação geral\n",
        "- O modelo apresenta **ótimo desempenho no treino (F1 ≈ 0.97)**, mas ainda generaliza bem para validação e teste.  \n",
        "- **Teste com F1 ≈ 0.86**: forte equilíbrio entre precisão (90%) e recall (82%).  \n",
        "- Comparado a modelos anteriores, a Random Forest consegue **capturar mais falhas** sem perder tanta precisão.  \n",
        "- O recall elevado no teste indica que o modelo **consegue identificar a maior parte das falhas reais**, característica essencial para este tipo de problema.  \n",
        "\n",
        "A Random Forest se mostra uma das abordagens mais promissoras até agora, com **bom trade-off entre recall e precisão** e baixa tendência a overfitting.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5c1fec19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c1fec19",
        "outputId": "e4541dcf-e9dc-4798-9f7a-cb22b93f9a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved ... RandomForestClassifier(class_weight={0: 1, 1: 7}, criterion='entropy',\n",
            "                       max_depth=15, max_features=0.7, min_samples_leaf=3,\n",
            "                       min_samples_split=3, n_estimators=500, random_state=42)\n"
          ]
        }
      ],
      "source": [
        "experimento.save(name=\"Random Forrest Classifier\", model=rf_model, metrics=metrics, complex_weight=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08756d1f",
      "metadata": {
        "id": "08756d1f"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "> Esta linha salva o modelo **Random Forest** treinado usando o método `save` do objeto `experimento`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e26b46ee",
      "metadata": {
        "id": "e26b46ee"
      },
      "source": [
        "## 3.5 Ada boosting:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf79082",
      "metadata": {
        "id": "ebf79082"
      },
      "source": [
        "##### 3.5.1 fine tunning ada boosting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7c8dc54f",
      "metadata": {
        "id": "7c8dc54f"
      },
      "outputs": [],
      "source": [
        "# # comentamos pois ja encontramos os parametros, descomentar caso queria rodar novamente - tempo de execucao aproximadamente: 382 minutos\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "# from sklearn.metrics import make_scorer, f1_score\n",
        "# from sklearn.ensemble import AdaBoostClassifier\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# import optuna\n",
        "\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "# def objective(trial):\n",
        "#     max_depth = trial.suggest_categorical(\"max_depth\", [7, 17])\n",
        "#     min_samples_leaf = trial.suggest_categorical(\"min_samples_leaf\", [3, 6])\n",
        "#     min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 0.00153, 0.001532, log=True)\n",
        "#     class_weight_1 = trial.suggest_categorical(\"class_weight_1\", [2, 9])\n",
        "\n",
        "#     n_estimators = trial.suggest_categorical(\"n_estimators\", [377, 477])\n",
        "#     learning_rate = trial.suggest_float(\"learning_rate\", 0.05309, 0.0531, log=True)\n",
        "\n",
        "#     base_tree = DecisionTreeClassifier(\n",
        "#         max_depth=max_depth,\n",
        "#         min_samples_leaf=min_samples_leaf,\n",
        "#         min_impurity_decrease=min_impurity_decrease,\n",
        "#         class_weight={0:1, 1:class_weight_1},\n",
        "#         random_state=42\n",
        "#     )\n",
        "\n",
        "#     ada_model = AdaBoostClassifier(\n",
        "#         estimator=base_tree,\n",
        "#         n_estimators=n_estimators,\n",
        "#         learning_rate=learning_rate,\n",
        "#         random_state=42\n",
        "#     )\n",
        "\n",
        "#     scores = cross_val_score(ada_model, x_train, y_train.values.ravel(), cv=skf, scoring=f1_scorer)\n",
        "#     return scores.mean()\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(objective, n_trials=1000)\n",
        "\n",
        "# print(\"Melhores parâmetros:\", study.best_trial.params)\n",
        "# print(\"Melhor F1 médio na validação:\", study.best_trial.value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1455734c",
      "metadata": {
        "id": "1455734c"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula realizamos a **otimização de hiperparâmetros do modelo AdaBoost** com um classificador base do tipo **Árvore de Decisão**, para maximizar o **F1-score**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Parâmetros otimizados\n",
        "- **Base Learner (Árvore de Decisão):**\n",
        "  - `max_depth`: controla a profundidade máxima da árvore (7 ou 17 testados). Árvores mais profundas capturam mais padrões, mas podem superajustar.  \n",
        "  - `min_samples_leaf`: número mínimo de amostras em cada folha.  \n",
        "  - `min_impurity_decrease`: exige uma redução mínima na impureza para permitir uma divisão, ajudando a evitar divisões irrelevantes.  \n",
        "  - `class_weight={0:1, 1:k}`: ajusta o peso da classe positiva (1), essencial para lidar com o **desbalanceamento**.  \n",
        "\n",
        "- **AdaBoost:**\n",
        "  - `n_estimators`: número de classificadores fracos combinados (377 ou 477 testados). Mais estimadores tendem a aumentar a estabilidade.  \n",
        "  - `learning_rate`: taxa de aprendizado que controla a contribuição de cada classificador fraco. Valores pequenos (como ~0.053) tornam o modelo mais conservador e estável.  \n",
        "\n",
        "---\n",
        "\n",
        "### Estratégia de validação\n",
        "- Foi aplicada **validação cruzada estratificada (5 folds)** para garantir que a proporção entre classes fosse preservada em cada divisão.  \n",
        "- A métrica usada foi o **F1-score**, pois equilibra precisão e recall, ideal em problemas com classes desbalanceadas.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa\n",
        "O AdaBoost combina vários **classificadores fracos (árvores pouco profundas)** para formar um modelo mais robusto.  \n",
        "A escolha correta de hiperparâmetros é crucial, pois:  \n",
        "- Árvores muito profundas ou com muitos estimadores podem levar a **overfitting**.  \n",
        "- Árvores muito rasas ou poucos estimadores podem levar a **underfitting**.  \n",
        "\n",
        "Assim, a otimização garantiu que o modelo fosse configurado de forma equilibrada, maximizando o F1-score sem perder generalização.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "867c9519",
      "metadata": {
        "id": "867c9519"
      },
      "source": [
        "### 3.5.2 fit best parameter config Adaboosting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2e04cb92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "2e04cb92",
        "outputId": "93082de8-381d-4f9e-c560-048cd9509f6d"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import AdaBoostClassifier\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# base_tree = DecisionTreeClassifier(\n",
        "#         max_depth=17,\n",
        "#         min_samples_leaf=3,\n",
        "#         min_impurity_decrease=0.0015308770816931528,\n",
        "#         class_weight={0:1, 1:9},\n",
        "#         random_state=42\n",
        "#     )\n",
        "\n",
        "# ada_model = AdaBoostClassifier(\n",
        "#     estimator=base_tree,\n",
        "#     n_estimators=477,\n",
        "#     learning_rate= 0.05309756471678731,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "\n",
        "# ada_model.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# y_train_probs = ada_model.predict_proba(x_train)[:, 1]\n",
        "# y_test_probs = ada_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "# metrics_val = cv_metrics_precision_recall_f1(ada_model, x_train, y_train, n_splits=5, random_state=42)\n",
        "# metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "# metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "# display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1444bf6",
      "metadata": {
        "id": "d1444bf6"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "Nesta célula foi treinado o modelo **AdaBoost** com base em uma **Árvore de Decisão** configurada com os melhores parâmetros obtidos na otimização.  \n",
        "\n",
        "### Configuração do modelo\n",
        "- **Base Learner (DecisionTreeClassifier):**\n",
        "  - `max_depth=17`: árvore relativamente profunda, capturando interações complexas.  \n",
        "  - `min_samples_leaf=3`: garante robustez mínima em cada folha.  \n",
        "  - `min_impurity_decrease≈0.00153`: evita splits pouco relevantes.  \n",
        "  - `class_weight={0:1, 1:9}`: dá muito mais peso às falhas (classe positiva).  \n",
        "\n",
        "- **AdaBoostClassifier:**\n",
        "  - `n_estimators=477`: utiliza 477 árvores fracas combinadas.  \n",
        "  - `learning_rate≈0.053`: taxa de aprendizado baixa, evitando overajuste e dando peso equilibrado a cada árvore.  \n",
        "  - `random_state=42`: reprodutibilidade.  \n",
        "\n",
        "---\n",
        "\n",
        "### Métricas obtidas\n",
        "**Treino:**  \n",
        "- Precisão = **1.00**  \n",
        "- Recall = **1.00**  \n",
        "- F1 = **1.00**  \n",
        "\n",
        "**Validação cruzada (5 folds):**  \n",
        "- Precisão ≈ **0.87**  \n",
        "- Recall ≈ **0.73**  \n",
        "- F1 ≈ **0.79**  \n",
        "\n",
        "**Teste:**  \n",
        "- Precisão ≈ **0.93**  \n",
        "- Recall ≈ **0.80**  \n",
        "- F1 ≈ **0.86**  \n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação geral\n",
        "- No **treino**, o modelo atingiu métricas perfeitas ``(overfitting evidente)``.  \n",
        "- Porém, na **validação** e **teste**, as métricas são bem mais realistas, com **F1 ≈ 0.86 no teste**, mostrando excelente equilíbrio entre precisão e recall.  \n",
        "- O modelo é capaz de **capturar a maioria das falhas (recall alto ≈ 0.80)**, ao mesmo tempo em que mantém **baixa taxa de falsos positivos (precisão ≈ 0.93)**.  \n",
        "\n",
        ">Conclusão: O AdaBoost com Decision Trees demonstrou ser um **modelo extremamente competitivo**, equilibrando bem as métricas e se mostrando mais robusto que modelos anteriores.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fb24a974",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb24a974",
        "outputId": "038a417d-2e38-432c-9ee1-d1ee3bc64617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved ... AdaBoostClassifier(estimator=DecisionTreeClassifier(class_weight={0: 1, 1: 9},\n",
            "                                                    max_depth=17,\n",
            "                                                    min_impurity_decrease=0.0015308770816931528,\n",
            "                                                    min_samples_leaf=3,\n",
            "                                                    random_state=42),\n",
            "                   learning_rate=0.05309756471678731, n_estimators=477,\n",
            "                   random_state=42)\n"
          ]
        }
      ],
      "source": [
        "experimento.save(name=\"Ada Boosting Classifier\", model=ada_model, metrics=metrics, complex_weight=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498522b5",
      "metadata": {
        "id": "498522b5"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "> Este comando utiliza o método `save` do objeto `experimento` para armazenar o modelo **AdaBoost** (Adaptive Boosting) treinado. **Em resumo**, a linha salva o modelo AdaBoost treinado, juntamente com seu nome, métricas de desempenho e peso de complexidade, no sistema de gerenciamento de experimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a48a8e91",
      "metadata": {
        "id": "a48a8e91"
      },
      "source": [
        "## 3.6 Gradient Boosting:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a22a7cf",
      "metadata": {
        "id": "7a22a7cf"
      },
      "source": [
        "##### 3.6.1 fine tunning Gradient Boosting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "779ca349",
      "metadata": {
        "id": "779ca349"
      },
      "outputs": [],
      "source": [
        "# # Comentamos pois já encontramos os parametros, descomentar caso queria rodar novamente - tempo de execucao aproximadamente: 428 minutos\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "# from sklearn.metrics import make_scorer, f1_score\n",
        "# from sklearn.ensemble import GradientBoostingClassifier\n",
        "# import optuna\n",
        "\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# f1_scorer = make_scorer(f1_score, pos_label=1)\n",
        "\n",
        "# def objective(trial):\n",
        "#     max_depth = trial.suggest_int(\"max_depth\", 2, 21)\n",
        "#     min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
        "#     min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
        "#     min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 0.0, 0.01)\n",
        "#     subsample = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
        "#     n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
        "#     learning_rate = trial.suggest_float(\"learning_rate\", 0.005, 0.2, log=True)\n",
        "#     criterion = trial.suggest_categorical(\"criterion\", [\"squared_error\", \"friedman_mse\"])\n",
        "#     max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", 0.5, 0.7, 1.0])\n",
        "\n",
        "\n",
        "#     g_boosting = GradientBoostingClassifier(\n",
        "#         max_depth=max_depth,\n",
        "#         min_samples_leaf=min_samples_leaf,\n",
        "#         min_impurity_decrease=min_impurity_decrease,\n",
        "#         subsample=subsample,\n",
        "#         n_estimators=n_estimators,\n",
        "#         learning_rate=learning_rate,\n",
        "#         criterion=criterion,\n",
        "#         max_features=max_features,\n",
        "#         random_state=42\n",
        "#     )\n",
        "\n",
        "#     scores = cross_val_score(g_boosting, x_train, y_train.values.ravel(), cv=skf, scoring=f1_scorer)\n",
        "#     return scores.mean()\n",
        "\n",
        "# study = optuna.create_study(direction=\"maximize\")\n",
        "# study.optimize(objective, n_trials=1000)\n",
        "\n",
        "# print(\"Melhores parâmetros:\", study.best_trial.params)\n",
        "# print(\"Melhor F1 no teste:\", study.best_trial.value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf9aaec",
      "metadata": {
        "id": "edf9aaec"
      },
      "source": [
        "**Legenda (Otimização – Gradient Boosting):**\n",
        "\n",
        "Nesta célula foi realizada a **otimização de hiperparâmetros** para o modelo **Gradient Boosting**, com o objetivo de **maximizar o F1-score**.  \n",
        "\n",
        "---\n",
        "\n",
        "### Parâmetros otimizados\n",
        "- **Estrutura das árvores:**\n",
        "  - `max_depth`: profundidade máxima das árvores. Valores maiores capturam interações complexas, mas aumentam risco de overfitting.  \n",
        "  - `min_samples_leaf`: número mínimo de amostras por folha, evitando folhas muito pequenas.  \n",
        "  - `min_samples_split`: número mínimo de amostras necessário para uma divisão.  \n",
        "  - `min_impurity_decrease`: garante que divisões só ocorram quando realmente relevantes.  \n",
        "\n",
        "- **Gradient Boosting:**\n",
        "  - `subsample`: proporção de dados usada em cada árvore. Valores < 1.0 tornam o modelo mais **estocástico**, aumentando a robustez.  \n",
        "  - `n_estimators`: número de árvores combinadas.  \n",
        "  - `learning_rate`: controla a contribuição de cada árvore. Valores baixos (como 0.05) reduzem overfitting.  \n",
        "  - `criterion`: mede a qualidade das divisões (`friedman_mse` ou `squared_error`).  \n",
        "  - `max_features`: número de features considerado em cada split.  \n",
        "\n",
        "---\n",
        "\n",
        "### Estratégia de validação\n",
        "- **Validação cruzada estratificada (5 folds)** preservando a proporção de classes.  \n",
        "- Métrica: **F1-score**, equilibrando precisão e recall para lidar com classes desbalanceadas.  \n",
        "\n",
        "---\n",
        "\n",
        "### Justificativa\n",
        "O Gradient Boosting constrói **árvores sequenciais**, onde cada nova árvore corrige erros das anteriores.  \n",
        "A otimização é essencial porque:\n",
        "- Muitos estimadores e profundidade alta podem causar **overfitting**.  \n",
        "- Poucos estimadores ou taxa de aprendizado muito alta podem levar a **underfitting**.  \n",
        "\n",
        "A busca encontrou um equilíbrio entre **complexidade das árvores** e **taxa de aprendizado**, maximizando o desempenho.  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c08d67a7",
      "metadata": {
        "id": "c08d67a7"
      },
      "source": [
        "#### 3.6.2 fit best parameter config Gradient Boosting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "f54a7939",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "f54a7939",
        "outputId": "adbb8f0d-2f88-4dc5-b258-753d5e5cf658"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# g_boosting = GradientBoostingClassifier(\n",
        "#                     max_depth=17,\n",
        "#                     min_samples_leaf=8,\n",
        "#                     min_impurity_decrease=0.0010266802349129212,\n",
        "#                     subsample=0.866563526312947,\n",
        "#                     n_estimators=265,\n",
        "#                     learning_rate=0.04636051072855432,\n",
        "#                     criterion='friedman_mse',\n",
        "#                     max_features=1.0,\n",
        "#                     random_state=42\n",
        "#                 )\n",
        "\n",
        "# g_boosting.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# y_train_probs = g_boosting.predict_proba(x_train)[:, 1]\n",
        "# y_test_probs = g_boosting.predict_proba(x_test)[:, 1]\n",
        "\n",
        "# metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "# metrics_val = cv_metrics_precision_recall_f1(g_boosting, x_train, y_train, n_splits=5, random_state=42)\n",
        "# metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "# metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "# display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83baa975",
      "metadata": {
        "id": "83baa975"
      },
      "source": [
        "**Legenda (Modelo – Gradient Boosting):**\n",
        "\n",
        "Aqui foi treinado o **GradientBoostingClassifier** com os melhores parâmetros encontrados pela otimização.  \n",
        "\n",
        "---\n",
        "\n",
        "### Configuração do modelo\n",
        "- `max_depth=17`: árvores relativamente profundas, capturam relações complexas.  \n",
        "- `min_samples_leaf=8`: garante folhas mais estáveis.  \n",
        "- `min_impurity_decrease≈0.0010`: exige relevância mínima para splits.  \n",
        "- `subsample≈0.87`: usa amostras parcialmente aleatórias, aumentando a generalização.  \n",
        "- `n_estimators=265`: número moderado de árvores, suficiente para capturar padrões.  \n",
        "- `learning_rate≈0.046`: taxa de aprendizado baixa, reduzindo risco de overfitting.  \n",
        "- `criterion=\"friedman_mse\"`: otimização padrão do scikit-learn para boosting.  \n",
        "- `max_features=1.0`: utiliza todas as variáveis em cada split.  \n",
        "- `random_state=42`: reprodutibilidade.  \n",
        "\n",
        "---\n",
        "\n",
        "### Métricas obtidas\n",
        "**Treino:**  \n",
        "- Precisão = **1.00**  \n",
        "- Recall = **1.00**  \n",
        "- F1 = **1.00**  \n",
        "\n",
        "**Validação cruzada (5 folds):**  \n",
        "- Precisão ≈ **0.89**  \n",
        "- Recall ≈ **0.72**  \n",
        "- F1 ≈ **0.80**  \n",
        "\n",
        "**Teste:**  \n",
        "- Precisão ≈ **0.88**  \n",
        "- Recall ≈ **0.74**  \n",
        "- F1 ≈ **0.80**  \n",
        "\n",
        "---\n",
        "\n",
        "### Interpretação geral\n",
        "- No **treino**, o modelo atingiu métricas perfeitas ``(overfitting claro)``.  \n",
        "- Já na **validação** e **teste**, o desempenho foi consistente (F1 ≈ 0.80), mostrando boa capacidade de generalização.  \n",
        "- O modelo apresenta **alto equilíbrio** entre precisão e recall, sendo capaz de capturar falhas com boa cobertura sem exagerar nos falsos positivos.  \n",
        "\n",
        "Conclusão: O Gradient Boosting mostrou-se **um dos modelos mais equilibrados**, combinando **alto recall** (captura a maioria dos casos positivos) com **boa precisão**, mantendo robustez em dados não vistos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f958c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4f958c2",
        "outputId": "b02c7ffd-abd0-465b-e646-c79125efcde0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'g_boosting' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m experimento.save(name=\u001b[33m\"\u001b[39m\u001b[33mGradient Boosting Classifier\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[43mg_boosting\u001b[49m, metrics=metrics, complex_weight=\u001b[32m6\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'g_boosting' is not defined"
          ]
        }
      ],
      "source": [
        "# experimento.save(name=\"Gradient Boosting Classifier\", model=g_boosting, metrics=metrics, complex_weight=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94b64f24",
      "metadata": {
        "id": "94b64f24"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "> Esta linha de código é responsável por salvar o modelo **Gradient Boosting** treinado no gerenciador de experimentos. **Em resumo**, o comando registra o modelo Gradient Boosting, seu nome, suas métricas e seu peso de complexidade para futuras análises e comparações."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b7288c9",
      "metadata": {
        "id": "6b7288c9"
      },
      "source": [
        "# 4.0 comparando os modelos treinados individualmente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfee7d7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "bfee7d7a",
        "outputId": "4dc29ae5-24f4-4991-9631-8fc1e35d4104"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Complex Weight</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Train F1</th>\n",
              "      <th>Validation Precision</th>\n",
              "      <th>Validation Recall</th>\n",
              "      <th>Validation F1</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Test F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>1</td>\n",
              "      <td>0.58042</td>\n",
              "      <td>0.31439</td>\n",
              "      <td>0.40786</td>\n",
              "      <td>0.58042</td>\n",
              "      <td>0.31439</td>\n",
              "      <td>0.40786</td>\n",
              "      <td>0.69444</td>\n",
              "      <td>0.37879</td>\n",
              "      <td>0.49020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Support Vector Classifier</td>\n",
              "      <td>3</td>\n",
              "      <td>0.97525</td>\n",
              "      <td>0.74621</td>\n",
              "      <td>0.84549</td>\n",
              "      <td>0.97525</td>\n",
              "      <td>0.74621</td>\n",
              "      <td>0.84549</td>\n",
              "      <td>0.84091</td>\n",
              "      <td>0.56061</td>\n",
              "      <td>0.67273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>2</td>\n",
              "      <td>0.86585</td>\n",
              "      <td>0.80682</td>\n",
              "      <td>0.83529</td>\n",
              "      <td>0.86585</td>\n",
              "      <td>0.80682</td>\n",
              "      <td>0.83529</td>\n",
              "      <td>0.79688</td>\n",
              "      <td>0.77273</td>\n",
              "      <td>0.78462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forrest Classifier</td>\n",
              "      <td>4</td>\n",
              "      <td>0.94928</td>\n",
              "      <td>0.99242</td>\n",
              "      <td>0.97037</td>\n",
              "      <td>0.94928</td>\n",
              "      <td>0.99242</td>\n",
              "      <td>0.97037</td>\n",
              "      <td>0.90000</td>\n",
              "      <td>0.81818</td>\n",
              "      <td>0.85714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ada Boosting Classifier</td>\n",
              "      <td>5</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.92982</td>\n",
              "      <td>0.80303</td>\n",
              "      <td>0.86179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>6</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.74242</td>\n",
              "      <td>0.80328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Model  Complex Weight  Train Precision  \\\n",
              "0           Logistic Regression               1          0.58042   \n",
              "1     Support Vector Classifier               3          0.97525   \n",
              "2      Decision Tree Classifier               2          0.86585   \n",
              "3     Random Forrest Classifier               4          0.94928   \n",
              "4       Ada Boosting Classifier               5          1.00000   \n",
              "5  Gradient Boosting Classifier               6          1.00000   \n",
              "\n",
              "   Train Recall  Train F1  Validation Precision  Validation Recall  \\\n",
              "0       0.31439   0.40786               0.58042            0.31439   \n",
              "1       0.74621   0.84549               0.97525            0.74621   \n",
              "2       0.80682   0.83529               0.86585            0.80682   \n",
              "3       0.99242   0.97037               0.94928            0.99242   \n",
              "4       1.00000   1.00000               1.00000            1.00000   \n",
              "5       1.00000   1.00000               1.00000            1.00000   \n",
              "\n",
              "   Validation F1  Test Precision  Test Recall  Test F1  \n",
              "0        0.40786         0.69444      0.37879  0.49020  \n",
              "1        0.84549         0.84091      0.56061  0.67273  \n",
              "2        0.83529         0.79688      0.77273  0.78462  \n",
              "3        0.97037         0.90000      0.81818  0.85714  \n",
              "4        1.00000         0.92982      0.80303  0.86179  \n",
              "5        1.00000         0.87500      0.74242  0.80328  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "experimento.summary().drop([\"Model Params\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4519b9b0",
      "metadata": {
        "id": "4519b9b0"
      },
      "source": [
        "**Legenda** (Tabela de Métricas)\n",
        "\n",
        "> A tabela resultante é o placar final de desempenho para cada modelo, separada em três conjuntos de dados:\n",
        ">\n",
        "> -   **Métricas `Train`**: Desempenho do modelo nos dados que ele usou para treinar.\n",
        "> -   **Métricas `Validation`**: Desempenho em dados de validação cruzada, usados para ajustar o modelo e evitar *overfitting*.\n",
        "> -   **Métricas `Test`**: **As mais importantes**. Mostram como o modelo generaliza para dados completamente novos, que ele nunca viu antes.\n",
        ">\n",
        "> **Observação Importante**: Note que os modelos `Ada Boosting` e `Gradient Boosting` têm performance perfeita (1.00) nos dados de treino. Isso é um forte sinal de **overfitting**, onde o modelo \"decorou\" as respostas do treino, mas seu desempenho em dados de teste, embora bom, é inferior. O `Random Forest` parece ter o melhor equilíbrio entre complexidade e performance nos dados de teste (`Test F1` de 0.85714).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3402821",
      "metadata": {
        "id": "b3402821"
      },
      "source": [
        "# 5.0 Enssemble votting classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30214e2",
      "metadata": {
        "id": "f30214e2"
      },
      "outputs": [],
      "source": [
        "model_svm = experimento.records[1].get(\"Model Obj\")\n",
        "model_dtree = experimento.records[2].get(\"Model Obj\")\n",
        "model_rf = experimento.records[3].get(\"Model Obj\")\n",
        "model_adab = experimento.records[4].get(\"Model Obj\")\n",
        "model_gb = experimento.records[5].get(\"Model Obj\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7a79f7",
      "metadata": {
        "id": "ee7a79f7"
      },
      "source": [
        "**Legenda**\n",
        "\n",
        "> A ideia aqui é criar um \"supermodelo\" combinando alguns dos melhores modelos individuais. Em vez de escolher apenas um, usamos um comitê onde os modelos \"votam\" na melhor resposta.\n",
        "\n",
        "> O código abaixo recupera os objetos de modelo que foram salvos anteriormente no `experimento`. Cada linha carrega um modelo específico para uma nova variável.\n",
        "\n",
        "`model_svm = experimento.records[1].get(\"Model Obj\")`\n",
        "\n",
        "`model_dtree = experimento.records[2].get(\"Model Obj\")`\n",
        "\n",
        "`...`\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9000819c",
      "metadata": {
        "id": "9000819c"
      },
      "source": [
        "#### 5.1 fit Voting Classifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab246e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "3ab246e3",
        "outputId": "2496165e-bb3d-460f-acc1-507aee6a73d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': {'precision': 1.0, 'recall': 0.93939, 'f1': 0.96875},\n",
              " 'val': {'precision': 0.91422, 'recall': 0.67424, 'f1': 0.77444},\n",
              " 'test': {'precision': 0.92593, 'recall': 0.75758, 'f1': 0.83333}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_soft = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('svm', model_svm),\n",
        "        ('dtree', model_dtree),\n",
        "        ('rf', model_rf),\n",
        "        ('adab', model_adab),\n",
        "        ('gb', model_gb)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "voting_soft.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "y_train_probs = voting_soft.predict_proba(x_train)[:, 1]\n",
        "y_test_probs = voting_soft.predict_proba(x_test)[:, 1]\n",
        "\n",
        "metrics_train = precision_recall_f1(y_train, y_train_probs, threshold=0.5)\n",
        "metrics_val = cv_metrics_precision_recall_f1(voting_soft, x_train, y_train, n_splits=5, random_state=42)\n",
        "metrics_test = precision_recall_f1(y_test, y_test_probs, threshold=0.5)\n",
        "metrics = {\"train\": metrics_train, \"val\": metrics_val,\"test\": metrics_test}\n",
        "display(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2fba2ac",
      "metadata": {
        "id": "a2fba2ac"
      },
      "source": [
        "### Legenda: Análise do Modelo Ensemble (Soft Voting Classifier)\n",
        "\n",
        "> Este bloco descreve a criação e o desempenho de um **meta-modelo**, o `VotingClassifier`. A sua estratégia não é aprender do zero, mas sim combinar as previsões de vários modelos mais simples para tomar uma decisão final mais robusta e precisa, como um \"comitê de especialistas\".\n",
        "\n",
        "---\n",
        "\n",
        "### Configuração do Modelo\n",
        "\n",
        "> A configuração deste modelo consiste em definir quais \"especialistas\" farão parte do comitê e como a decisão final será tomada.\n",
        ">\n",
        "> -   `estimators=[...]`: Define os cinco modelos que participarão da votação:\n",
        ">     -   Support Vector Machine (`svm`)\n",
        ">     -   Decision Tree (`dtree`)\n",
        ">     -   Random Forest (`rf`)\n",
        ">     -   AdaBoost (`adab`)\n",
        ">     -   Gradient Boosting (`gb`)\n",
        ">\n",
        "> -   `voting='soft'`: **Este é o parâmetro mais importante**. Em vez de uma votação simples onde cada modelo dá um voto e a maioria vence (*hard voting*), o **soft voting** funciona de forma mais inteligente:\n",
        ">     -   Ele coleta a **probabilidade** (ou a \"confiança\") de cada modelo para cada classe.\n",
        ">     -   Em seguida, calcula a média dessas probabilidades.\n",
        ">     -   A previsão final é a classe que tiver a maior probabilidade média. Essa abordagem geralmente produz resultados superiores, pois leva em conta a confiança de cada especialista em sua decisão.\n",
        "\n",
        "---\n",
        "\n",
        "### Métricas de Desempenho\n",
        "\n",
        "> Os resultados obtidos pelo comitê de modelos foram:\n",
        ">\n",
        "> -   **Dados de Treino:**\n",
        ">     -   Precisão: **1.0**\n",
        ">     -   Recall: **~0.94**\n",
        ">     -   F1-Score: **~0.97**\n",
        ">\n",
        "> -   **Validação Cruzada (5 folds):**\n",
        ">     -   Precisão: **~0.91**\n",
        ">     -   Recall: **~0.67**\n",
        ">     -   F1-Score: **~0.77**\n",
        ">\n",
        "> -   **Dados de Teste:**\n",
        ">     -   Precisão: **~0.93**\n",
        ">     -   Recall: **~0.77**\n",
        ">     -   F1-Score: **~0.84**\n",
        "\n",
        "---\n",
        "\n",
        "### Análise e Conclusão\n",
        "\n",
        "> -   **Força na União:** O modelo combinado alcançou um **F1-Score de 0.84** nos dados de teste, um desempenho muito forte e competitivo, superando vários dos modelos individuais.\n",
        "> -   **Alta Precisão:** A **precisão de 0.93** no teste é um destaque. Isso significa que, quando o modelo prevê um resultado positivo, ele está correto em 93% das vezes. É um modelo muito confiável em suas afirmações positivas.\n",
        "> -   **Generalização Sólida:** Embora o desempenho no treino seja quase perfeito (sinal de um leve *overfitting* herdado dos modelos base), a performance em dados de teste prova que a combinação conseguiu criar um modelo generalista e robusto.\n",
        ">\n",
        "> **Em resumo**, o Soft Voting Classifier demonstrou ser uma excelente estratégia, agregando o poder preditivo de diferentes algoritmos para criar um \"supermodelo\" com alta precisão e um desempenho geral muito equilibrado em dados desconhecidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639bb1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "639bb1f7",
        "outputId": "f1a8f8b9-e05f-4859-b08c-d3b5ea37d878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model saved ... VotingClassifier(estimators=[('svm',\n",
            "                              SVC(C=99.90622647684818,\n",
            "                                  class_weight={0: 1, 1: 1}, probability=True,\n",
            "                                  random_state=42)),\n",
            "                             ('dtree',\n",
            "                              DecisionTreeClassifier(class_weight={0: 1, 1: 1},\n",
            "                                                     max_depth=11,\n",
            "                                                     min_impurity_decrease=0.0001,\n",
            "                                                     min_samples_leaf=5,\n",
            "                                                     random_state=42)),\n",
            "                             ('rf',\n",
            "                              RandomForestClassifier(class_weight={0: 1, 1: 7},\n",
            "                                                     criterion='entropy',\n",
            "                                                     max_depth=15,\n",
            "                                                     max_features=...\n",
            "                                                                                  min_impurity_decrease=0.0015308770816931528,\n",
            "                                                                                  min_samples_leaf=3,\n",
            "                                                                                  random_state=42),\n",
            "                                                 learning_rate=0.05309756471678731,\n",
            "                                                 n_estimators=477,\n",
            "                                                 random_state=42)),\n",
            "                             ('gb',\n",
            "                              GradientBoostingClassifier(learning_rate=0.04636051072855432,\n",
            "                                                         max_depth=17,\n",
            "                                                         max_features=1.0,\n",
            "                                                         min_impurity_decrease=0.0010266802349129212,\n",
            "                                                         min_samples_leaf=8,\n",
            "                                                         n_estimators=265,\n",
            "                                                         random_state=42,\n",
            "                                                         subsample=0.866563526312947))],\n",
            "                 voting='soft')\n"
          ]
        }
      ],
      "source": [
        "experimento.save(name=\"Soft Voting Classifier\", model=voting_soft, metrics=metrics, complex_weight=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56496c1",
      "metadata": {
        "id": "f56496c1"
      },
      "source": [
        "**Legenda:**\n",
        "\n",
        "> Esta linha de código é responsável por salvar o modelo **Soft Voting Classifier** treinado no gerenciador de experimentos. **Em resumo**, o comando registra o modelo, seu nome, suas métricas e seu peso de complexidade para futuras análises e comparações."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc8e14d",
      "metadata": {
        "id": "8cc8e14d"
      },
      "source": [
        "# 6.0 Resultados e Selecao Modelo FInal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f376ad",
      "metadata": {
        "id": "69f376ad"
      },
      "outputs": [],
      "source": [
        "df_experimento =  experimento.summary().drop([\"Model Params\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43dabd06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "43dabd06",
        "outputId": "2121ad37-cae5-43a1-9d00-b1cd94733e0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Complex Weight</th>\n",
              "      <th>Train Precision</th>\n",
              "      <th>Train Recall</th>\n",
              "      <th>Train F1</th>\n",
              "      <th>Validation Precision</th>\n",
              "      <th>Validation Recall</th>\n",
              "      <th>Validation F1</th>\n",
              "      <th>Test Precision</th>\n",
              "      <th>Test Recall</th>\n",
              "      <th>Test F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>1</td>\n",
              "      <td>0.58042</td>\n",
              "      <td>0.31439</td>\n",
              "      <td>0.40786</td>\n",
              "      <td>0.58042</td>\n",
              "      <td>0.31439</td>\n",
              "      <td>0.40786</td>\n",
              "      <td>0.69444</td>\n",
              "      <td>0.37879</td>\n",
              "      <td>0.49020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Support Vector Classifier</td>\n",
              "      <td>3</td>\n",
              "      <td>0.97525</td>\n",
              "      <td>0.74621</td>\n",
              "      <td>0.84549</td>\n",
              "      <td>0.97525</td>\n",
              "      <td>0.74621</td>\n",
              "      <td>0.84549</td>\n",
              "      <td>0.84091</td>\n",
              "      <td>0.56061</td>\n",
              "      <td>0.67273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>2</td>\n",
              "      <td>0.86585</td>\n",
              "      <td>0.80682</td>\n",
              "      <td>0.83529</td>\n",
              "      <td>0.86585</td>\n",
              "      <td>0.80682</td>\n",
              "      <td>0.83529</td>\n",
              "      <td>0.79688</td>\n",
              "      <td>0.77273</td>\n",
              "      <td>0.78462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forrest Classifier</td>\n",
              "      <td>4</td>\n",
              "      <td>0.94928</td>\n",
              "      <td>0.99242</td>\n",
              "      <td>0.97037</td>\n",
              "      <td>0.94928</td>\n",
              "      <td>0.99242</td>\n",
              "      <td>0.97037</td>\n",
              "      <td>0.90000</td>\n",
              "      <td>0.81818</td>\n",
              "      <td>0.85714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ada Boosting Classifier</td>\n",
              "      <td>5</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.92982</td>\n",
              "      <td>0.80303</td>\n",
              "      <td>0.86179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>6</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.87500</td>\n",
              "      <td>0.74242</td>\n",
              "      <td>0.80328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Soft Voting Classifier</td>\n",
              "      <td>7</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.93939</td>\n",
              "      <td>0.96875</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.93939</td>\n",
              "      <td>0.96875</td>\n",
              "      <td>0.92593</td>\n",
              "      <td>0.75758</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Model  Complex Weight  Train Precision  \\\n",
              "0           Logistic Regression               1          0.58042   \n",
              "1     Support Vector Classifier               3          0.97525   \n",
              "2      Decision Tree Classifier               2          0.86585   \n",
              "3     Random Forrest Classifier               4          0.94928   \n",
              "4       Ada Boosting Classifier               5          1.00000   \n",
              "5  Gradient Boosting Classifier               6          1.00000   \n",
              "6        Soft Voting Classifier               7          1.00000   \n",
              "\n",
              "   Train Recall  Train F1  Validation Precision  Validation Recall  \\\n",
              "0       0.31439   0.40786               0.58042            0.31439   \n",
              "1       0.74621   0.84549               0.97525            0.74621   \n",
              "2       0.80682   0.83529               0.86585            0.80682   \n",
              "3       0.99242   0.97037               0.94928            0.99242   \n",
              "4       1.00000   1.00000               1.00000            1.00000   \n",
              "5       1.00000   1.00000               1.00000            1.00000   \n",
              "6       0.93939   0.96875               1.00000            0.93939   \n",
              "\n",
              "   Validation F1  Test Precision  Test Recall  Test F1  \n",
              "0        0.40786         0.69444      0.37879  0.49020  \n",
              "1        0.84549         0.84091      0.56061  0.67273  \n",
              "2        0.83529         0.79688      0.77273  0.78462  \n",
              "3        0.97037         0.90000      0.81818  0.85714  \n",
              "4        1.00000         0.92982      0.80303  0.86179  \n",
              "5        1.00000         0.87500      0.74242  0.80328  \n",
              "6        0.96875         0.92593      0.75758  0.83333  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_experimento"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bd8026e",
      "metadata": {
        "id": "4bd8026e"
      },
      "source": [
        "> Esta tabela final consolida o desempenho de todos os modelos testados. A decisão sobre o melhor modelo não se baseia apenas na performance máxima, mas também no **custo-benefício**, que considera o **peso de complexidade** de cada um. Um modelo mais simples e com desempenho quase igual ao do melhor é, muitas vezes, a escolha mais inteligente e prática.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f292dcb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "f292dcb1",
        "outputId": "b283598b-7c26-4a1b-bd44-a3d13530d1b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = df_experimento[[\"Model\", \"Train F1\", \"Validation F1\", \"Test F1\"]].copy()\n",
        "\n",
        "bar_width = 0.25\n",
        "x = np.arange(len(df['Model']))\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.bar(x - bar_width, df['Train F1'], width=bar_width, label='Train F1', color='#627CFF')\n",
        "plt.bar(x, df['Validation F1'], width=bar_width, label='Validation F1', color='#FF6961')\n",
        "plt.bar(x + bar_width, df['Test F1'], width=bar_width, label='Test F1', color='#00C49A')\n",
        "\n",
        "plt.xlabel('Fitted Model', fontsize=12)\n",
        "plt.ylabel('Classifier Metrics', fontsize=12)\n",
        "plt.title('Comparativo de F1-Score entre Modelos (Treino, Validação e Teste)', fontsize=16, fontweight='bold')\n",
        "plt.xticks(ticks=x, labels=df['Model'], rotation=45, ha='right')\n",
        "plt.ylim(0.3, 1.05)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fc1265d",
      "metadata": {
        "id": "5fc1265d"
      },
      "source": [
        "### Legenda: Resultados Finais e Seleção do Modelo\n",
        "\n",
        "\n",
        "### Análise de Custo vs. Benefício\n",
        "\n",
        "O critério de seleção será a combinação de duas métricas-chave:\n",
        "1.  **Benefício (Performance):** O **`Test F1-Score`**, que nos diz quão bem o modelo generaliza para dados novos.\n",
        "2.  **Custo (Esforço):** O **`Complex Weight`**, que representa o quão \"caro\" o modelo é em termos de treinamento, manutenção e risco de overfitting.\n",
        "\n",
        "Vamos comparar os dois melhores candidatos sob essa ótica:\n",
        "\n",
        "* **Ada Boosting Classifier:**\n",
        "    * **Benefício (Test F1):** 0.862 (O mais alto)\n",
        "    * **Custo (Complexidade):** 5 (Alto)\n",
        "* **Random Forest Classifier:**\n",
        "    * **Benefício (Test F1):** 0.857 (Quase idêntico ao primeiro)\n",
        "    * **Custo (Complexidade):** 4 (Menor que o AdaBoost)\n",
        "\n",
        "---\n",
        "\n",
        "### Veredito e Justificativa da Escolha\n",
        "\n",
        "Apesar do `Ada Boosting Classifier` ter o maior F1-Score, a diferença para o `Random Forest Classifier` é mínima (**apenas 0.005**). No entanto, o Random Forest é um modelo **notavelmente menos complexo** (peso 4 vs. 5).\n",
        "\n",
        "\n",
        "\n",
        "Essa diferença de performance não justifica o aumento na complexidade. O **Random Forest** oferece o melhor retorno sobre o investimento: ele entrega um desempenho de ponta sendo, ao mesmo tempo, mais simples, rápido e potencialmente mais estável que o AdaBoost.\n",
        "\n",
        "---\n",
        "\n",
        "### Conclusão Final\n",
        "\n",
        "O **Random Forest Classifier é selecionado como o modelo final**. Ele representa o ponto ótimo entre **alta performance preditiva** e **eficiência computacional**, tornando-se a escolha mais pragmática e robusta para a implementação deste projeto."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce9c5f33",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exportação do Modelo Random Forest\n",
        "\n",
        "Vamos exportar o modelo **Random Forest** treinado para um arquivo `.joblib` para uso futuro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "95da7dbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo: None\n",
            "Tipo: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "\n",
            "Parâmetros do modelo:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': {0: 1, 1: 7}, 'criterion': 'entropy', 'max_depth': 15, 'max_features': 0.7, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 500, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Recuperar o modelo Random Forest do experimento\n",
        "# O Random Forest está na posição 3 do experimento.records\n",
        "rf_model = experimento.records[3].get(\"Model Obj\")\n",
        "\n",
        "# Verificar o modelo\n",
        "print(f\"Modelo: {experimento.records[3].get('Model Name')}\")\n",
        "print(f\"Tipo: {type(rf_model)}\")\n",
        "print(f\"\\nParâmetros do modelo:\")\n",
        "print(rf_model.get_params())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "eb4aa393",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Modelo Random Forest salvo com sucesso em 'random_forest_model.joblib'\n"
          ]
        }
      ],
      "source": [
        "# Salvar o modelo em arquivo .joblib\n",
        "joblib.dump(rf_model, 'random_forest_model.joblib')\n",
        "\n",
        "print(\"✅ Modelo Random Forest salvo com sucesso em 'random_forest_model.joblib'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce41378d",
      "metadata": {},
      "source": [
        "### Exportar modelo completo com métricas (Opcional)\n",
        "\n",
        "Se você quiser salvar o modelo junto com as métricas de desempenho e hiperparâmetros:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c4bc3dac",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Modelo completo com métricas salvo em 'random_forest_complete.joblib'\n"
          ]
        }
      ],
      "source": [
        "# Salvar modelo com informações adicionais\n",
        "model_info = {\n",
        "    'model': experimento.records[3].get(\"Model Obj\"),\n",
        "    'model_name': experimento.records[3].get(\"Model Name\"),\n",
        "    'metrics': {\n",
        "        'test_f1': experimento.records[3].get(\"Test F1 Score\"),\n",
        "        'test_precision': experimento.records[3].get(\"Test Precision\"),\n",
        "        'test_recall': experimento.records[3].get(\"Test Recall\"),\n",
        "        'test_accuracy': experimento.records[3].get(\"Test Accuracy\")\n",
        "    },\n",
        "    'hyperparameters': experimento.records[3].get(\"Model Params\")\n",
        "}\n",
        "\n",
        "joblib.dump(model_info, 'random_forest_complete.joblib')\n",
        "\n",
        "print(\"✅ Modelo completo com métricas salvo em 'random_forest_complete.joblib'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfd7a8e1",
      "metadata": {},
      "source": [
        "### Como carregar o modelo posteriormente\n",
        "\n",
        "Para usar o modelo salvo em outro script ou notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "814abb7f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Código de exemplo para carregar o modelo (comentado)\n"
          ]
        }
      ],
      "source": [
        "# Carregar apenas o modelo\n",
        "# rf_model_loaded = joblib.load('random_forest_model.joblib')\n",
        "\n",
        "# Ou carregar o modelo completo com métricas\n",
        "# model_data = joblib.load('random_forest_complete.joblib')\n",
        "# rf_model_loaded = model_data['model']\n",
        "# print(f\"Métricas: {model_data['metrics']}\")\n",
        "\n",
        "# Fazer previsões com o modelo carregado\n",
        "# predictions = rf_model_loaded.predict(X_new)\n",
        "\n",
        "print(\"Código de exemplo para carregar o modelo (comentado)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.11.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
